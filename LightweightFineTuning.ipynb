{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33300a2be8748cf9071052b43431747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 3.11M/3.11M [00:00<00:00, 10.4MB/s]\n",
      "Downloading data: 100%|██████████| 72.8k/72.8k [00:00<00:00, 441kB/s]\n",
      "Downloading data: 100%|██████████| 148k/148k [00:00<00:00, 901kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e0b18dd8e34000b9de6723594da2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77718f4012b43639ce4a1ae036e7d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914d11018415478b8eee0a001edbb4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the Stanford Sentiment Treebank dataset\n",
    "# See: https://huggingface.co/datasets/sst2\n",
    "\n",
    "# Define the splits we want to load (training and testing)\n",
    "splits = [\"train\", \"validation\"]\n",
    "# Load the SST-2 dataset splits using a dictionary comprehension.\n",
    "# 'load_dataset' function fetches the dataset from Hugging Face's dataset repository.\n",
    "# 'glue' is the broader dataset collection, 'sst2' is the specific dataset for sentiment analysis.\n",
    "# Iterating over the splits list to load both training and testing sets.\n",
    "dataset = {split: load_dataset(\"glue\", \"sst2\", split=split) for split in splits}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb8e62",
   "metadata": {},
   "source": [
    "Load tokenizer and tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cecc1c8cb0143eb966a1e98f06cc147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffe431de3354c06b0e42f89d9f8a68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609e4b3f21a446449921e786e5db977d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90048333c7c44595be4a5952109070a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f991a4c4d24cbe834d2cd01ab6202f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load the tokenzier\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set EOS (end of sentence) TOKEN as PAD TOKEN\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4745eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6ae999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"Preprocess the imdb dataset by returning tokenized examples.\n",
    "    :examples:\n",
    "    \n",
    "    :returns:\n",
    "    \"\"\"\n",
    "    # convert the text data in a list of tokens using tokenizer, truncating\n",
    "    # the text to the maximum lenght and pad shorter sequences to a uniform lenght\n",
    "    # return the result\n",
    "    return tokenizer(examples['sentence'], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579a5bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af5f3ca9f8e4ce29bded749e071b224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0925b76fa303428a96baef5fd015ea87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store the tokenized datasets.\n",
    "tokenized_ds = {}\n",
    "# Iterate over each data split ('train' and 'test').\n",
    "for split in splits:\n",
    "    # Apply the preprocess_function to the dataset corresponding to the current split.\n",
    "    # The 'map' function applies the preprocess_function to each example in the dataset.\n",
    "    # 'batched=True' allows processing multiple examples at once for efficiency.\n",
    "    tokenized_ds[split] = dataset[split].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f6f3b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hide new secretions from the parental units \n",
      "[24717, 649, 3200, 507, 422, 262, 21694, 4991, 220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n"
     ]
    }
   ],
   "source": [
    "# print a sample of sentence and its tokenization in train subset\n",
    "print(tokenized_ds[\"train\"][0]['sentence'])\n",
    "print(tokenized_ds[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "555720be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 's a charming and often affecting journey . \n",
      "[270, 705, 82, 257, 23332, 290, 1690, 13891, 7002, 764, 220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n"
     ]
    }
   ],
   "source": [
    "# print a sample of sentence and its tokenization in validation subset\n",
    "print(tokenized_ds[\"validation\"][0]['sentence'])\n",
    "print(tokenized_ds[\"validation\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a6e263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddde877954f4764acc80ac5b730757c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model 'gpt-2' for sequence classification.\n",
    "# This model is designed for tasks like sentiment analysis where each sequence (like a sentence)\n",
    "# is classified into categories (like positive/negative).\n",
    "# here, we specify the number of labels (2 for sentiment classification),\n",
    "# id2label and label2id corresponding to POSITIVE and NEGATIVE labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained('gpt2',\n",
    "                                                      num_labels=2,\n",
    "                                                      id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "                                                      label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "120d60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's pad token id to match the tokenizer's pad token id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cce0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the parameters of the base model\n",
    "# Iterate over all the parameters of the base model.\n",
    "for param in model.base_model.parameters():\n",
    "    # freeze the base model disabling the gradient calculations for each parameter\n",
    "    # in the base model of \"gpt2\" model\n",
    "    # Set 'requires_grad' to False to freeze the parameters of the base model.\n",
    "    # Freezing prevents the weights of these layers from being updated during training.\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc209823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# check model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3e0a653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 'model.score' is the classification head that will be trained to adapt \n",
    "# the base model for our specific task (sentiment analysis in this case).\n",
    "model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17fac57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Function for compute tha accuracy metric\n",
    "    :eval_pred: a tuple with predictions and labels\n",
    "    \n",
    "    :returns: a dictionary with the mean accuracy\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    # Convert the predictions to discrete labels by taking the argmax,\n",
    "    # which is the index of the highest value in the prediction (logits).\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    # Calculate and return the accuracy as the mean of the instances where\n",
    "    # predictions match the true labels.\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84426b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Initialize the Trainer, a high-level API for training transformer models.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model_output\", # Directory where the model outputs will be saved.\n",
    "    learning_rate=2e-5, # Learning rate for the optimizer.\n",
    "    # Reduce the batch size if you don't have enough memory\n",
    "    per_device_train_batch_size=16, # Batch size for training per device.\n",
    "    per_device_eval_batch_size=16, # Batch size for evaluation per device.\n",
    "    num_train_epochs=1, # Number of training epochs.\n",
    "    weight_decay=0.01, # Weight decay for regularization.\n",
    "    evaluation_strategy=\"epoch\", # Evaluation is performed at the end of each epoch.\n",
    "    save_strategy=\"epoch\", # Model is saved at the end of each epoch.\n",
    "    load_best_model_at_end=True, # Load the best model at the end of training.\n",
    ")\n",
    "\n",
    "pretrain_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"], # The tokenized training dataset.\n",
    "    eval_dataset=tokenized_ds[\"validation\"], # The tokenized evaluation dataset.\n",
    "    tokenizer=tokenizer, # The tokenizer used for encoding the data.\n",
    "    # Data collator that will dynamically pad the batches during training.\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics, # Function to compute metrics during evaluation.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff8fd2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results before fine-tuning: {'eval_loss': 2.5617620944976807, 'eval_accuracy': 0.5091743119266054, 'eval_runtime': 13.049, 'eval_samples_per_second': 66.825, 'eval_steps_per_second': 4.215}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set before fine-tuning\n",
    "pretrain_results = pretrain_trainer.evaluate()\n",
    "\n",
    "# Print the evaluation results before fine-tuning\n",
    "print(\"Evaluation results before fine-tuning:\", pretrain_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model 'gpt-2' for sequence classification.\n",
    "# This model is designed for tasks like sentiment analysis where each sequence (like a sentence)\n",
    "# is classified into categories (like positive/negative).\n",
    "# here, we specify the number of labels (2 for sentiment classification),\n",
    "# id2label and label2id corresponding to POSITIVE and NEGATIVE labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained('gpt2',\n",
    "                                                      num_labels=2,\n",
    "                                                      id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "                                                      label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's pad token id to match the tokenizer's pad token id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 814,080 || all params: 125,253,888 || trainable%: 0.6499438963523432\n"
     ]
    }
   ],
   "source": [
    "# Create a PEFT Config for LoRA\n",
    "config = LoraConfig(\n",
    "                    r=8, # Rank\n",
    "                    lora_alpha=32,\n",
    "                    target_modules=['c_attn', 'c_proj'],\n",
    "                    lora_dropout=0.1,\n",
    "                    bias=\"none\",\n",
    "                    task_type=TaskType.SEQ_CLS\n",
    "                )\n",
    "\n",
    "peft_model = get_peft_model(model, config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8058a880b3741e5808b36ef1be9641e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c29812706bd471c82a2f2553baf1d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rename 'label' to 'labels' to match the Trainer's expectation\n",
    "tokenized_ds[\"train\"] = tokenized_ds[\"train\"].map(lambda e: {'labels': e['label']}, batched=True, remove_columns=['label'])\n",
    "tokenized_ds[\"validation\"] = tokenized_ds[\"validation\"].map(lambda e: {'labels': e['label']}, batched=True, remove_columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "758b8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds[\"train\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_ds[\"validation\"].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2423ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,  # Make sure to pass the PEFT model here\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./lora_model_output\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        logging_dir='./logs',  # If you want to log metrics and/or losses during training\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True, max_length=512),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6005226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='4210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/4210 22:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.350500</td>\n",
       "      <td>0.282903</td>\n",
       "      <td>0.888761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.274430</td>\n",
       "      <td>0.899083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4210, training_loss=0.380601579389776, metrics={'train_runtime': 1358.0802, 'train_samples_per_second': 99.183, 'train_steps_per_second': 3.1, 'total_flos': 4436193624975360.0, 'train_loss': 0.380601579389776, 'epoch': 2.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the training process\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cc23421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fine tuned PEFT model\n",
    "peft_model.save_pretrained(\"gpt-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForSequenceClassification\n",
    "\n",
    "NUM_LABELS = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\"gpt-lora\", num_labels=NUM_LABELS, ignore_mismatched_sizes=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's pad token id to match the tokenizer's pad token id\n",
    "lora_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Initialize the Trainer, a high-level API for training transformer models.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./data/sentiment_analysis\", # Directory where the model outputs will be saved.\n",
    "    learning_rate=2e-5, # Learning rate for the optimizer.\n",
    "    # Reduce the batch size if you don't have enough memory\n",
    "    per_device_train_batch_size=16, # Batch size for training per device.\n",
    "    per_device_eval_batch_size=16, # Batch size for evaluation per device.\n",
    "    num_train_epochs=1, # Number of training epochs.\n",
    "    weight_decay=0.01, # Weight decay for regularization.\n",
    "    evaluation_strategy=\"epoch\", # Evaluation is performed at the end of each epoch.\n",
    "    save_strategy=\"epoch\", # Model is saved at the end of each epoch.\n",
    "    load_best_model_at_end=True, # Load the best model at the end of training.\n",
    ")\n",
    "\n",
    "finetuned_trainer = Trainer(\n",
    "    model=lora_model,  # The fine-tuned PEFT model.\n",
    "    args=training_args,# Training arguments, defined above.\n",
    "    train_dataset=tokenized_ds[\"train\"], # The tokenized training dataset.\n",
    "    eval_dataset=tokenized_ds[\"validation\"], # The tokenized evaluation dataset.\n",
    "    tokenizer=tokenizer, # The tokenizer used for encoding the data.\n",
    "    # Data collator that will dynamically pad the batches during training.\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics, # Function to compute metrics during evaluation.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for the fine-tuned model: {'eval_loss': 0.2744295299053192, 'eval_accuracy': 0.8990825688073395, 'eval_runtime': 3.745, 'eval_samples_per_second': 232.842, 'eval_steps_per_second': 14.686}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the fine-tuned model on the validation set\n",
    "finetuned_results = finetuned_trainer.evaluate()\n",
    "\n",
    "# Print the evaluation results for the fine-tuned model\n",
    "print(\"Evaluation results for the fine-tuned model:\", finetuned_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
